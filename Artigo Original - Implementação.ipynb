{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Implementação - Processamento Digital de Imagens Aplicado a Identificação Automática de Placas de Trânsito</h1>\n",
    "\n",
    "Esta é a implementação do projeto \"Processamento Digital de Imagens Aplicado a Identificação Automática de Placas de Trânsito\", disponível em: http://ojs.unirg.edu.br/index.php/1/article/view/2280\n",
    "\n",
    "O artigo foi utilizado como referência para o desenvolvimento deste projeto. Foram utilizados métodos diferentes dos descritos no artigo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as pp\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "\n",
    "from collections import deque\n",
    "from skimage import data\n",
    "from skimage.color import rgb2hsv\n",
    "from skimage import filters\n",
    "from skimage import exposure\n",
    "from skimage import color, img_as_float\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Primeira etapa</h1>\n",
    "\n",
    "Ao  início  do  algoritmo,  é  lida  a  imagem  de  entrada  (no  espaço  de  cores  padrão RGB), em que se quer verificar a existência de uma placa de parada obrigatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaca\\Documents\\IFCE\\PDI\\Trabalho final\\Dataset\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), 'Dataset')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro do dataset, o programa vai pegar uma série de informações:\n",
    "\n",
    "- caminho: diretório das imagens\n",
    "- file: uma lista com o nome de todo arquivo que está na pasta Dataset\n",
    "\n",
    "O segundo 'for' vai pegar cada file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = []\n",
    "gray_data_set = []\n",
    "        \n",
    "for caminho, d, file in os.walk(path):\n",
    "    for filename in file:\n",
    "        \n",
    "        img = cv2.imread(os.path.join(caminho,filename))\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        data_set.append(img)\n",
    "        gray_data_set.append(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Segunda etapa</h1>\n",
    "\n",
    "Para  a  detecção  de  uma  placa  de  pare,  primeiramente  é  feita  a  separação  dos objetos  em  vermelho  do  restante  da  imagem. Esta  tarefa  é  realizada  convertendo  a imagem  para  o  espaço  de  cores  HSV (função rgb2hsv). Busca-se  por pixels com valores de matiz (hue) 10% mais próximos às extremidades iniciais e finais do conjunto possível de valores representados nesta banda (a matiz armazena as variações cromáticas  da  imagem  de  entrada  com  valores  compreendidos  entre  0  e 1) e com  um valor  de  saturação acima  de 50% (pois procura-se por cores mais puras). Isto  gera  uma máscara que é aplicada à imagem original separando os objetos com cor predominantemente vermelha dos demais objetos presentes na  imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_detection(img):\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    ## Gen lower mask (0-5) and upper mask (175-180) of RED\n",
    "    mask1 = cv2.inRange(img_hsv, (0,50,20), (5,255,255))\n",
    "    mask2 = cv2.inRange(img_hsv, (175,50,20), (180,255,255))\n",
    "\n",
    "    ## Merge the mask and crop the red regions\n",
    "    mask = cv2.bitwise_or(mask1, mask2 )\n",
    "    croped = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    return mask, croped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, somente são considerados objetos com dimensão de, no mínimo, 10% do tamanho total da imagem. Qualquer objeto detectado, com dimensão inferior a 10% da dimensão da imagem de entrada, é descartado pela chamada da função bwareaopen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension10(mask,img):\n",
    "    blur = cv2.blur(mask,(4,4))\n",
    "    mask = cv2.threshold(blur, 175 , 250, cv2.THRESH_BINARY)\n",
    "    mask = mask[1]\n",
    "    croped = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    return mask, croped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Terceira Etapa</h1>\n",
    "\n",
    "Após segmentar um objeto vermelho da imagem, onde uma possível placa de pare estará,  a  imagem  passa  por  um  processo  de detecção  de  bordas  pela  máscara  de gradiente  binário  nesta  imagem  segmentada,  utilizando  o  filtro  de  Sobel  aplicado  com  o auxílio de funções do software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plt.subplot(121),plt.imshow(croped,cmap = 'gray')\\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\\nplt.subplot(122),plt.imshow(edges,cmap = 'gray')\\nplt.title('Edge Image'), plt.xticks([]), plt.yticks([])\\nplt.show()\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def edge(croped):\n",
    "    edges = cv2.Canny(croped,100,200)\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois  da  aplicação  do  filtro  de Sobel,  é  possível  que  bordas  do mesmo  objeto fiquem  desconectadas.  Então  a  imagem  gerada  é dilatada  para  realizar  a  junção  de bordas de um mesmo objeto. Essa dilatação é feita através da função imdilate do Matlab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plt.subplot(121),plt.imshow(edges)\\nplt.title('Edge Image'), plt.xticks([]), plt.yticks([])\\nplt.subplot(122),plt.imshow(dilate)\\nplt.title('Edge Dilation'), plt.xticks([]), plt.yticks([])\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sobel(edges):\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    dilate = cv2.dilate(edges,kernel,iterations = 1)\n",
    "    \n",
    "    return dilate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Quarta Etapa</h1>\n",
    "\n",
    "Como  o  propósito  do  algoritmo  é  detectar  apenas  as  bordas  externas  de  uma possível  placa,  ao  resultado  do  processo  anterior,  é  aplicado outro  operador morfológico para  preencher  o  interior de  objetos conectados  (função imfill), resultando  em  uma imagem  onde todos  os objetos  com  bordas  externas  conectadas  estão  totalmente preenchidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seed(image):\n",
    "    w, h = image.shape\n",
    "    semente = np.zeros((w, h))\n",
    "    semente[:, :3] = 255 # Lateral esquerda\n",
    "    semente[:, (h-3):] = 255 # Lateral direita\n",
    "    \n",
    "    return semente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighborhood(x, y, w, h):\n",
    "    lista = deque()\n",
    "    \n",
    "    pontos = [(x-1,y), (x+1, y), (x,y-1), (x,y+1),\n",
    "              (x-1,y+1), (x+1, y+1), (x-1,y-1), (x+1,y-1),\n",
    "             ]\n",
    "    for p in pontos:\n",
    "        if (p[0]>=0 and p[1]>=0 and p[0]<w and p[1]<h):\n",
    "            lista.append((p[0], p[1]))\n",
    "            \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow_region(image, reg, epsilon=5):\n",
    "    w, h = image.shape\n",
    "    \n",
    "    fila = deque()\n",
    "    for x in range(w):\n",
    "        for y in range(h):\n",
    "            if reg[x,y]==255:\n",
    "                fila.append((x,y))\n",
    "                \n",
    "    while fila: \n",
    "        ponto = fila.popleft()\n",
    "        x = ponto[0]\n",
    "        y = ponto[1]\n",
    "\n",
    "        v_list = neighborhood(x, y, w, h)\n",
    "        for v in v_list:\n",
    "            v_x = v[0]\n",
    "            v_y = v[1]\n",
    "            if( (reg[v_x][v_y]!=255) and (abs(image[x][y]-image[v_x][v_y])<epsilon)):\n",
    "                reg[v_x][v_y] = 255\n",
    "                fila.append((v_x,v_y))\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente,  para  melhorar  a  definição  geométrica  do  objeto  detectado  na imagem, é realizada uma erosão com o auxílio da função imerode, cujo resultado é uma imagem mais bem definida do objeto de interesse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close(le):\n",
    "    kernel = np.ones((4,4),np.uint8)\n",
    "    closing = cv2.morphologyEx(le, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    cv2.imwrite('closing.jpg',closing)\n",
    "    return closing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Quinta Etapa</h1>\n",
    "\n",
    "Neste  ponto,  espera-se  ter  uma  imagem  binária  com  a  geometria  bem definida  do objeto de interesse (um objeto relativamente grande, na cor vermelha, que não esteja em contato com qualquer extremidade da imagem). Esta imagem é utilizada como entrada no algoritmo de detecção de retas pela transformada de Hough.\n",
    "Neste algoritmo, o primeiro passo  é  detectar  as  bordas  do  objeto  de entrada  e,  para  isto,  é  utilizado  o  detector  de bordas ótimo de Canny.\n",
    "\n",
    "Com o objeto segmentado e suas bordas detectadas, é aplicada a transformada de Hough  para  encontrar  as  retas  principais  presentes  na  imagem  da  placa. A partir do resultado da transformada de Hough, são selecionados, no máximo, oito linhas  na  imagem,  o  que  é  suficiente  para  detectar  uma  placa  de  pare.  As  linhas detectadas  com  distância  menor  ou  igual  a cinco  pixels  são  unidas  formando  uma  única linha e os segmentos com tamanho menor que sete pixels são descartados.\n",
    "\n",
    "As  retas  encontradas  são  salvas  em  uma  estrutura  de  dados  que  armazena as coordenadas dos pontos que determinam o início (em amarelo) e o final (em vermelho) de cada  reta.  A  partir  dessas  informações,  são  exibidas  na  imagem  original  as  retas detectadas que descrevem os limites da placa de pare na imagem original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_transform(img, x):\n",
    "    image = cv2.imread('closing.jpg')\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    kernel_size = 5\n",
    "    blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)\n",
    "\n",
    "    low_threshold = 50\n",
    "    high_threshold = 100\n",
    "    edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "    rho = 1  # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "    threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 30  # minimum number of pixels making up a line\n",
    "    max_line_gap = 30  # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(img) * 0  # creating a blank to draw lines on\n",
    "\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),min_line_length, max_line_gap)\n",
    "\n",
    "    #try:\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(line_image,(x1,y1),(x2,y2),(0,255,0),5)\n",
    "\n",
    "    # Draw the lines on the  image\n",
    "    lines_edges = cv2.addWeighted(image, 0.8, line_image, 1, 0)\n",
    "    path = os.path.join(os.getcwd(), 'Imagens-tratadas')\n",
    "    cv2.imwrite(os.path.join(path,'houghlines'+str(x)+'.jpg'),lines_edges)\n",
    "    \n",
    "    return line_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percorre as imagens do dataset, realiza as operações e salva as imagens em uma nova pasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/198 [00:00<?, ?it/s]<ipython-input-10-46c31f6ee4df>:19: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  if( (reg[v_x][v_y]!=255) and (abs(image[x][y]-image[v_x][v_y])<epsilon)):\n",
      "  1%|▊                                                                               | 2/198 [01:10<1:55:08, 35.25s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-35b9244d8766>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0msemente\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdilate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrow_region\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdilate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msemente\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mclosing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-46c31f6ee4df>\u001b[0m in \u001b[0;36mgrow_region\u001b[1;34m(image, reg, epsilon)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mv_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mv_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_x\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_y\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_x\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_y\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[0mreg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_x\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_y\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0mfila\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "x = 1\n",
    "\n",
    "for img in tqdm(data_set):    \n",
    "    mask, croped = red_detection(img)\n",
    "    mask, croped = dimension10(mask,img)\n",
    "    edges = edge(croped)\n",
    "    dilate = sobel(edges)\n",
    "    \n",
    "    semente = get_seed(dilate)\n",
    "    le = grow_region(dilate, semente, epsilon=5)\n",
    "    \n",
    "    closing = close(le)\n",
    "    line_image = hough_transform(img, x)\n",
    "    x += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
