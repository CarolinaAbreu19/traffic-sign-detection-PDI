{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Implementação - Modificação do projeto \"Processamento Digital de Imagens Aplicado a Identificação Automática de Placas de Trânsito\"</h1>\n",
    "\n",
    "Esta é a modificação proposta para a implementação do projeto \"Processamento Digital de Imagens Aplicado a Identificação Automática de Placas de Trânsito\", disponível em: http://ojs.unirg.edu.br/index.php/1/article/view/2280\n",
    "\n",
    "O artigo foi utilizado como referência para o desenvolvimento deste projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as pp\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "\n",
    "from collections import deque\n",
    "from skimage import data\n",
    "from skimage.color import rgb2hsv\n",
    "from skimage import filters\n",
    "from skimage import exposure\n",
    "from skimage import color, img_as_float\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Primeira etapa</h1>\n",
    "\n",
    "Ao  início  do  algoritmo,  é  lida  a  imagem  de  entrada  (no  espaço  de  cores  padrão RGB), em que se quer verificar a existência de uma placa de parada obrigatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaca\\Documents\\IFCE\\PDI\\Trabalho final\\Dataset-modificado\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), 'Dataset-modificado')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = []\n",
    "gray_data_set = []\n",
    "        \n",
    "for caminho, d, file in os.walk(path):\n",
    "    for filename in file:\n",
    "        \n",
    "        img = cv2.imread(os.path.join(caminho,filename))\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        data_set.append(img)\n",
    "        gray_data_set.append(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Segunda etapa</h1>\n",
    "\n",
    "Para  a  detecção  de  uma  placa  de  pare,  primeiramente  é  feita  a  separação  dos objetos  em  vermelho  do  restante  da  imagem. Esta  tarefa  é  realizada  convertendo  a imagem  para  o  espaço  de  cores  HSV (função rgb2hsv). Busca-se  por pixels com valores de matiz (hue) 10% mais próximos às extremidades iniciais e finais do conjunto possível de valores representados nesta banda (a matiz armazena as variações cromáticas  da  imagem  de  entrada  com  valores  compreendidos  entre  0  e 1) e com  um valor  de  saturação acima  de 50% (pois procura-se por cores mais puras). Isto  gera  uma máscara que é aplicada à imagem original separando os objetos com cor predominantemente vermelha dos demais objetos presentes na  imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_detection(img):\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    ## Gen lower mask (0-5) and upper mask (175-180) of RED\n",
    "    mask1 = cv2.inRange(img_hsv, (0,50,20), (5,255,255))\n",
    "    mask2 = cv2.inRange(img_hsv, (175,50,20), (180,255,255))\n",
    "\n",
    "    ## Merge the mask and crop the red regions\n",
    "    mask = cv2.bitwise_or(mask1, mask2 )\n",
    "    croped = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    return mask, croped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, somente são considerados objetos com dimensão de, no mínimo, 10% do tamanho total da imagem. Qualquer objeto detectado, com dimensão inferior a 10% da dimensão da imagem de entrada, é descartado pela chamada da função bwareaopen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension10(mask,img):\n",
    "    blur = cv2.blur(mask,(4,4))\n",
    "    mask = cv2.threshold(blur, 175 , 250, cv2.THRESH_BINARY)\n",
    "    mask = mask[1]\n",
    "    croped = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    return mask, croped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Terceira Etapa</h1>\n",
    "\n",
    "Após segmentar um objeto vermelho da imagem, onde uma possível placa de pare estará,  a  imagem  passa  por  um  processo  de detecção  de  bordas  pela  máscara  de gradiente  binário  nesta  imagem  segmentada,  utilizando  o  filtro  de  Sobel  aplicado  com  o auxílio de funções do software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge(croped):\n",
    "    edges = cv2.Canny(croped,100,200)\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois  da  aplicação  do  filtro  de Sobel,  é  possível  que  bordas  do mesmo  objeto fiquem  desconectadas.  Então  a  imagem  gerada  é dilatada  para  realizar  a  junção  de bordas de um mesmo objeto. Essa dilatação é feita através da função imdilate do Matlab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel(edges):\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    dilate = cv2.dilate(edges,kernel,iterations = 1)\n",
    "    \n",
    "    return dilate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Quarta Etapa</h1>\n",
    "\n",
    "Como  o  propósito  do  algoritmo  é  detectar  apenas  as  bordas  externas  de  uma possível  placa,  ao  resultado  do  processo  anterior,  é  aplicado outro  operador morfológico para  preencher  o  interior de  objetos conectados  (função imfill), resultando  em  uma imagem  onde todos  os objetos  com  bordas  externas  conectadas  estão  totalmente preenchidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seed(image):\n",
    "    w, h = image.shape\n",
    "    semente = np.zeros((w, h))\n",
    "    semente[:, :3] = 255 # Lateral esquerda\n",
    "    semente[:, (h-3):] = 255 # Lateral direita\n",
    "    \n",
    "    return semente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighborhood(x, y, w, h):\n",
    "    lista = deque()\n",
    "    \n",
    "    pontos = [(x-1,y), (x+1, y), (x,y-1), (x,y+1),\n",
    "              (x-1,y+1), (x+1, y+1), (x-1,y-1), (x+1,y-1),\n",
    "             ]\n",
    "    for p in pontos:\n",
    "        if (p[0]>=0 and p[1]>=0 and p[0]<w and p[1]<h):\n",
    "            lista.append((p[0], p[1]))\n",
    "            \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow_region(image, reg, epsilon=5):\n",
    "    w, h = image.shape\n",
    "    \n",
    "    fila = deque()\n",
    "    for x in range(w):\n",
    "        for y in range(h):\n",
    "            if reg[x,y]==255:\n",
    "                fila.append((x,y))\n",
    "                \n",
    "    while fila: \n",
    "        ponto = fila.popleft()\n",
    "        x = ponto[0]\n",
    "        y = ponto[1]\n",
    "\n",
    "        v_list = neighborhood(x, y, w, h)\n",
    "        for v in v_list:\n",
    "            v_x = v[0]\n",
    "            v_y = v[1]\n",
    "            if( (reg[v_x][v_y]!=255) and (abs(image[x][y]-image[v_x][v_y])<epsilon)):\n",
    "                reg[v_x][v_y] = 255\n",
    "                fila.append((v_x,v_y))\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close(le):\n",
    "    kernel = np.ones((4,4),np.uint8)\n",
    "    closing = cv2.morphologyEx(le, cv2.MORPH_CLOSE, kernel)\n",
    "    cv2.imwrite('closing.jpg',closing)\n",
    "    return closing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente,  para  melhorar  a  definição  geométrica  do  objeto  detectado  na imagem, é realizada uma erosão com o auxílio da função imerode, cujo resultado é uma imagem mais bem definida do objeto de interesse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Quinta Etapa</h1>\n",
    "\n",
    "Neste  ponto,  espera-se  ter  uma  imagem  binária  com  a  geometria  bem definida  do objeto de interesse (um objeto relativamente grande, na cor vermelha, que não esteja em contato com qualquer extremidade da imagem). Esta imagem é utilizada como entrada no algoritmo de detecção de retas pela transformada de Hough.\n",
    "Neste algoritmo, o primeiro passo  é  detectar  as  bordas  do  objeto  de entrada  e,  para  isto,  é  utilizado  o  detector  de bordas ótimo de Canny.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cannyClose(closing):\n",
    "    copyClose = np.uint8(closing)\n",
    "    edges = cv2.Canny(copyClose,10,20)\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em vez de utilizar a Transformação de Hough, foi utilizado detecção de contornos a partir da borda da segmentação da placa. Para finalizar, é plotado um retângulo ao redor da placa observada, tendo-se como referência  os  pontos  extremos  que  delimitam  (acima,  abaixo,  à esquerda  e  à  direita)  a região provável de localização da placa na imagem de entrada.\n",
    "\n",
    "As imagens com as placas detectadas são salvas em uma nova pasta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawContourn(edges,img,a):\n",
    "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    print(\"Number of Contours found = \" + str(len(contours)))\n",
    "    cv2.drawContours(img, contours, -1, (0, 255, 0), 3)\n",
    "    for contour in contours:\n",
    "        # Find bounding rectangles\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Draw the rectangle\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "\n",
    "    path = os.path.join(os.getcwd(), 'Novas-imagens')\n",
    "    cv2.imwrite(os.path.join(path,'contourn'+str(a)+'.jpg'),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]<ipython-input-10-46c31f6ee4df>:19: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  if( (reg[v_x][v_y]!=255) and (abs(image[x][y]-image[v_x][v_y])<epsilon)):\n",
      "  2%|█▋                                                                                 | 1/50 [00:05<04:23,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▎                                                                               | 2/50 [00:12<04:40,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▉                                                                              | 3/50 [00:19<04:55,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▋                                                                            | 4/50 [00:25<04:41,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▎                                                                          | 5/50 [00:32<04:53,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▉                                                                         | 6/50 [01:18<13:23, 18.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▌                                                                       | 7/50 [01:24<10:30, 14.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                     | 8/50 [01:29<08:13, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▉                                                                    | 9/50 [01:38<07:21, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 10/50 [01:55<08:27, 12.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████                                                                | 11/50 [02:04<07:36, 11.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▋                                                              | 12/50 [02:08<05:53,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▎                                                            | 13/50 [02:51<12:03, 19.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▉                                                           | 14/50 [02:58<09:20, 15.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▌                                                         | 15/50 [03:36<13:04, 22.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▏                                                       | 16/50 [03:58<12:33, 22.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▉                                                      | 17/50 [04:04<09:31, 17.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▌                                                    | 18/50 [04:10<07:29, 14.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████▏                                                  | 19/50 [04:15<05:47, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 20/50 [04:32<06:34, 13.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████▍                                               | 21/50 [04:40<05:29, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 8\n",
      "Number of Contours found = 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▋                                            | 23/50 [05:13<05:58, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▋                                            | 23/50 [05:14<06:09, 13.68s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ff7c51f487ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0msemente\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdilate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrow_region\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdilate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msemente\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mclosing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-46c31f6ee4df>\u001b[0m in \u001b[0;36mgrow_region\u001b[1;34m(image, reg, epsilon)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mv_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_x\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_y\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_x\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_y\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0mreg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_x\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv_y\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[0mfila\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "a = 1\n",
    "\n",
    "for img in tqdm(data_set):    \n",
    "    mask, croped = red_detection(img)\n",
    "    mask, croped = dimension10(mask,img)\n",
    "    edges = edge(croped)\n",
    "    dilate = sobel(edges)\n",
    "    \n",
    "    semente = get_seed(dilate)\n",
    "    le = grow_region(dilate, semente, epsilon=5)\n",
    "    \n",
    "    closing = close(le)\n",
    "    edges = cannyClose(closing)\n",
    "    drawContourn(edges, img, a)\n",
    "    \n",
    "    a += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
